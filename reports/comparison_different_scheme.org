#+TITLE: Theoretical Comparison with Different Scheme
#+AUTHOR: Gun Woo Park

* Preface
This document is design for communication with different stochastic scheme. 

* Simplified Boltzmann distribution
Let assumed that there is $Np$ particles on the system, and $Nc$ chains per particle can act association. For fixed positions, I will try to finding the probability for micro-state that is based on the potential of associations.

For convenience, let assumed that the potential exerted on associated chain as Gaussian:
\begin{equation}
u_G(\mathbf{r}) = \frac{N_D}{2}r^2,
\end{equation}
where $\mathbf{r}$ is end-to-end vector for the chain. For convenience, the all physical quantities are non-dimensional. In 2-dimensional system, it becomes just square of the distance.

Since there are $Nc*Np$ chains on the system, the potential of the system is given by
\begin{equation}
U = \sum_{i=1}^{Nc*Np}u_G,
\end{equation}
which is sum over all potentials for individual chains.

Here we have to think that the both chain ends can be detached from its originate bead or not. In former sense, our problem is related with how we arrange the $Nc*Np$ chains on whole possible state while the latter one is we arrange $Nc$ chains to its associated state per beads.

** Chains can be freely transfer based on state probability
For simplicity, let assumed that there are 3 particles exist (Np=3), and 3 chains per each particles are subject to association. Let $p_1 = (0, 0)$, $p_2 = (1, 1)$, and $p_3 = (0, -2)$, then the dimensionless distance becomes $r_{12} = \sqrt{2}$, $r_{13} = 2$, and $r_{23} = \sqrt{10}$. Therefore, potential level for individual chains can be categorized as roof($=u_{11}=u_{22}=u_{33} = 0$), $u_{12} = 2$, $u_{13} = 4$, and $u_{23} = 10$, in this specific example. Therefore, we have 6 state (4 out of 6 can be distinguishable based on potential energy of state - 3 degeneracy -). For simplicity, I will use all the indistinguishable 6 states.

In this case, we have to arrange 9 (=Np*Nc) chains to the 6 state based on potential. The number of possible state on this case can be computed by combinations with repetition:
\begin{equation}
\left(\left(\begin{array}{c} n \\ k \end{array}\right)\right) = \left(\begin{array}{c} n +k - 1 \\ k \end{array}\right) = \frac{(n+k-1)!}{k!(n-1)!},
\end{equation}
the reason will be described in later time.

In this specific example, we have 2002 states (220 distinguishable states), which is very large even for this very simplified system. This is the reason we need to perform stochastic simulation with more realistic system (larger particles and larger chain numbers). If we account the all possible micro-state based on previous combinatorial search, we can have Boltzmann distribution for the potential of given state:
\begin{equation}
P'^{i} = \exp(-U^{i})\qquad\textrm{with }U^{i} = \sum_{j=1}^{Nc*Np}u^{i}_{j},
\end{equation}
where $u^{i}_{j}$ is potential for j-th chain in the i-th particle. 
The partition function is sum of the probability over all the state:
\begin{equation}
Z = \sum_{i=1}^{Ns}\exp(-U^{i}),
\end{equation}
where $Ns$ is number of micro-state which is 2002 in this specific example.
Finally, we have normalized probability that follows Boltzmann distribution:
\begin{equation}
P^{i} = P'^{i}/Z.
\end{equation}

For this simplified example, we have spectrum for potential energy state as figure [[fig:state_map_log]] that shows there are variety energy spectrum. The highest level refer that the all chains are in roof state that is occurred 55 times out of 2002 times with probability 1.593e-02. The second level related with there only one association with the smallest association potential, $u_{12}$: 45 times with probability 2.156e-03, and so on. In this specialized example, we can compute average number of association as
\begin{equation}
\langle NAS \rangle \approx 0*0.876263 + 1*(0.097028 + 0.023635) + 2*(0.002527 + 0.000454) = 0.127,
\end{equation}
which means 0.127 chains out of 9 chains are association, which is approximately 1.41% of chains are associated. Note that the 0.127 chain is not really doable for our simulation since it would be integer number. Of course, we can generalize this scheme for the bigger space. 

Note that the rated results represent 0.999909 probability of micro-state, and $u_{23}=10$ is not involved any of the represented results because $\exp(-10) = 4.54\times 10^{-5}$ is quite rare to capture in this scheme. This might be good clue to suggest cut-off radius for the all possible state that reduce dramatically. It is noteworthy that the $r_{23} = \sqrt{10} \approx 3.16$, which is not so much big radius. 


** Chains cannot be fully detached its originate bead
This prevent to transfer chains from one bead to other beads. Recall the previous example, the number of state for specific chain becomes 3 from 6. To be specific, if we think a single chain attached to bead 1, the possible state for this single chain is $u_{11}$ without degeneracy, $u_{12}$, and $u_{13}$. There is no $u_{23}$ since this chain cannot be detached from bead 1. Hence, the number of possible arrangement largely reduced in this case in comparison with the previous approach. 

From the given working hypothesis, we count the way of arrangement for 3 chains for first bead, for the second, and so on. The first bead case was simplified with
\begin{equation}
\left(\left(\begin{array}{c} 3 \\ 3\end{array}\right)\right) = \left(\begin{array}{c} 5 \\ 3\end{array}\right) = \frac{5!}{3!2!} = 10,
\end{equation}
which means we have only 10 micro-state for bead 1. Each beads contribute 10 micro-state, then the consequence of the all micro-state becomes $10^3$ which is approximately half of the previous example, 2002.

In this case, we can simplified the probability map that is based on each single bead:
\begin{equation}
P'^{i}_{k} = \exp(-U^{i}_{k}),
\end{equation}
where subscript k denote the k-th bead. 
The partition function for this case can be categorized with index k:
\begin{equation}
Z_{k} = \sum_{i=1}^{10}P'^{i}_{k},
\end{equation}
which implies
\begin{equation}
P^{i}_{k} = \exp(-U^{i}_{k})/Z_{k}.
\end{equation}
On this regards, the all possible probability of state can be accounted by
\begin{equation}
P^{(i,j,k)} = P^{i}_{1}\cdot P^{j}_{2} \cdot P^{k}_{3} \equiv \frac{\exp\left(-(U^{i}_1 + U^{j}_2 + U^{k}_3)\right)}{Z_1Z_2Z_3},
\end{equation}
still the subscript 1,2,3 denote the particles and index i,j,k denote the index for state with each particles.

In consequence, we can use individual state level and generalization simply conditional probability between i,j,k-th state level. The results described in figure [[fig:state_map_log_constraint]] which shows that higher probability to association (3.3%).


# Here is working hypothesis of this analysis:
# 1. Both chain ends cannot be detached from its originate bead: prevent the chain movement.
# 2. The probability of each beads independent to other beads: partitioning the overall complexity.


# \begin{equation}
# U = \sum_{i=1}^{Np}U^{i} \equiv \sum_{i=1}^{Np}\sum_{j=1}^{Nc}u_G^{i,j},
# \end{equation}
# where $u_G^{i,j}$ denote the chain index is $i,j$.


* Stochastic Simulation
For given position of particles, decision for the association should follows Boltzmann distribution that reported in the previous section. If we recall the number of micro-state with repeated combinations, even 3 beads system with 3 chains per beads make 2002 micro-state and simplified version make 1000 micro-state. For reasonable size of box, if beads of the system is 640 and 25 chains per beads are associable, then number of states becomes
\begin{align}
Ns_1 &= \left(\left(\begin{array}{c} C(N_p, 2) + N_p\\ N_cN_p \end{array}\right)\right) = \left(\left(\begin{array}{c} 205,120 \\ 16,000 \end{array}\right)\right) = \left(\begin{array}{c} 221,119 \\ 16,000\end{array}\right) = \frac{221,119!}{16,000!205,119!},  \\
Ns_2 &= \left(\left(\begin{array}{c} N_p + 1 \\ N_c\end{array}\right)\right)^{N_p} = \left(\left(\begin{array}{c} 641 \\ 25\end{array}\right)\right)^{640} = \left(\begin{array}{c} 665 \\ 25\end{array}\right)^{640} = \left(\frac{665!}{25!640!}\right)^{640},
\end{align}
where $C(N_p, 2)$ is also combination but used inside of binary expression in order to avoid complications, and $Ns_1$ is for freely transferable chain scheme while $Ns_1$ is number of micro-state for constraint chain scheme. Even if $Ns_2 < Ns_1$, *it still too large to compute in theoretical pathway*.
On this regards, we cannot avoid stochastic simulation in order to have stationary distribution from given position vectors.

** Originally used scheme
Let assumed that the opposite site of selected chain end attached to k-th bead, the selection probability follows the Boltzmann factor divided by sum of all possible Boltzmann factor. Before going further, let assumed that the given index set for j is already sorted with increasing order based on Boltzmann factor: $i>j \Leftrightarrow \exp(-u_{ik}) > \exp(-u_{jk})$, and define $Z_k(n)$ be sum over Boltzmann factor from index 1 to index n: $Z_k(n) = \sum_{i=1}^{n}\exp(-u_{ik})$. In this treatment, the index function, $I(p)$ where $p\in [0,1)$, becomes
\begin{equation}
I(p) = \left\{\begin{array}{cl} 
1 & \textrm{if } 0 \leq p < Z_k(1)/Z_k(N_p), \\
2 & \textrm{if } Z_k(1)/Z_k(N_p) \leq p < Z_k(2)/Z_k(N_p), \\
\vdots & \\
N_p & \textrm{if } Z_k(N_p -1)/Z_k(N_p) \leq p < 1.
\end{array} \right.
\end{equation}
Therefore, for randomly given $p$, the selected chain ends attach to the $I(p)$-th bead.

** Boltzmann Distribution
For simplification, let assumed that we are visiting *single chain end* in each stochastic steps. In the selected chain ends regarded as 'transition state' that automatically allows the following action. The first working hypothesis is that /whenever we visited a single chain end, it is automatically transition state without any probability generation/. 
Then, we have to choose a bead where this chain will attach. Since we are using Boltzmann distribution, the chain end should following Boltzmann factor, i.e., the ratio between expected probability for taking action and remaining probability:
\begin{equation}
\frac{\exp(-U')}{\exp(-U)} = \exp(-(U'-U)),
\end{equation}
where prime denote the expected potential when new action is taken. It is of importance that the previous action probability is based on the whenever the target is specified. So, we have to determine what is the target. 
In principle, the action of selected chain can be categorized by association, dissociation, and movement of association. The potential for association, of course, becomes adding one more connector potential to the system since the potential for roof chain is zero. Let $U$ be the original potential of the system, and $u$ be potential for new connector, the Boltzmann factor becomes
\begin{equation}
\frac{\exp(-(U+u))}{\exp(-U)}=C_{A}\exp(-u).
\end{equation}
In the case for dissociation with the same notation, it is inverse of association:
\begin{equation}
\frac{\exp(-U)}{\exp(-(U+u))} = C_{D}\exp(u).
\end{equation}
For movement of association, the boltzmann factor becomes multiplication between dissociation of the original state (A) and association of new state (B):
\begin{equation}
\frac{\exp(-U)}{\exp(-(U+u_A))}\frac{\exp(-(U+u_B))}{\exp(-U)} = C_{M}\exp(-(u_B - u_A)).
\end{equation}
Note that the $C_A, C_D, C_M$ are nomalization constants that is not specified up to now.

** Metropolis and Detailed Balance Equation
Let $\pi$ be equilibrium distribution and $P$ is transition probability, the detailed balance equation for the reversible Markov chain can be expressed by
\begin{equation}
\pi(s)P(s\to s') = \pi(s')P(s'\to s),
\end{equation}
where $s$ and $s'$ are states. In this case, the equilibrium distribution, $\pi$, is controlled by the transition probability, $P$, which is decomposed by proposal distribution, $q$, and acceptance probability, $\alpha$:
\begin{equation}
P(s\to s') = q(s\to s')\alpha(s\to s').
\end{equation}
which implies
\begin{equation}
\alpha(s\to s') = \frac{P(s\to s')}{q(s\to s')}.
\end{equation}
The acceptance ratio is given by the ratio of acceptance probability
\begin{equation}
A(s\to s') = \min\left\{1, \frac{\alpha(s\to s')}{\alpha(s'\to s)}\right\} = \min\left\{1, \frac{P(s\to s') q(s'\to s)}{P(s'\to s) q(s \to s')}\right\}.
\end{equation}
With the condition of $g(s\to s') = g(s'\to s)$, the acceptance is given by
\begin{equation}
A(s\to s') = \min\left\{1, \frac{P(s\to s')}{P(s'\to s)}\right\},
\end{equation}
where $P$ is given by Boltzmann distribution in this case.
The basic Metropolis-Hasting algorithm is used the following steps:
1. randomly pick an initial state, $s$;
2. randomly pick a target state, $s'$, based on the suggestion probability $g(s\to s')$;
3. accept the transition based on the acceptance ratio, $A$.  When $A$ is higher than unity, the transition is automatically allowed.
4. iterate until the system reaching equilibrium distribution.

For simplification and without violate the suggested scheme, the propose (suggestion) probability $g$ is given by uniformly, which means the suggestion probability is given by 
\begin{equation}
q(s_i\to s_j) = \frac{1}{N_p -1} \approx \frac{1}{N_p}\quad\textrm{for }N_p \gg 1.
\end{equation}

*** Start with Single Associable Case: Reversible Markov Chain
Let assumed that we picked up the chain end that attached to $k$-th bead. The target to attach is randomly suggested, say $i$. Then the state change of the system is very localized by the selected chain:
\begin{equation}
P_{ik} = \exp(-u_{ik}).
\end{equation}
Since the probability for selection and acceptance are free from the other connectivity information, we can localize the global distribution function, $\pi$, into local distribution function, $\pi_{ik}$, without loss of generality. The detail balance for this /very/ localized case can be
\begin{equation}
\pi_{ik}(1)P_{ik}(1\to 0) = \pi_{ik}(0)P_{ik}(0\to 1),
\end{equation}
and the acceptance ratio is given by
\begin{equation}
A_{ik}(0\to 1) = \min\left\{1, \frac{P_{ik}(0\to 1)}{P_{ik}(1\to 0)}\right\} = \min\left\{1, \frac{C^{A}_{ik}\exp(-u_{ik})}{C^{D}_{ik}\exp(u_{ii})}\right\} = \min\left\{1, \frac{C^{A}_{ik}}{C^{D}_{ik}}\exp(-u_{ik})\right\},
\end{equation}
where $C^{A}_{ik}$ and $C^{D}_{ik}$ are normalization factors between i-th and k-th beads for association and dissociation, respectively.


# Let $\pi^{k}(\mathscr{I}_k)$ be the local distribution function for the $k$-th bead where $\mathscr{I}_k$ be the connection information 
#  probability to association with $i$-th bead is given by $C \exp(-u_{ik})$.
#  then the detailed balance equation is expressed by
# \begin{equation}
# \pi_{k}(i) P(
# \end{equation}
# Let $\pi_{ik}$ be the equilibrium probability for state $ik$, the detailed balance equation is defined 
# For given pair i and j, detail balance equation can be expressed by
# \begin{equation}
# \pi_{ik}(1)P_{ik}(1\to 0) = \pi_{ik}(0)P_{ik}(0\to 1),
# \end{equation}
# where $P$ is the Markov transition proability and 1 denote there is one association while 0 denote no association. The transition probability decomposed into suggestion, $q$, and acceptance probability, $\alpha$:
# \begin{equation}
# P_{ik}(s) = q_{ik}(s)\alpha_{ik}(s).
# \end{equation}
# For Metropolis algorithm, it is of importance that the suggestion algorithm for the detailed balance equation should be symmetric:
# \begin{equation}
# q_{ik}(0\to 1) = q_{ik}(1 \to 0).
# \end{equation}

# Let assumed that we already have the target bead that the selected chain end will attached for. The algorithm for the /suggestion/ should be defined clearly, but the simplest case can be random selection among the all the possible suggestions. Ideally, the suggestion for the connection can be equally probable:
# \begin{equation}
# q_{ik} = \frac{1}{N_p -1}
# \end{equation}
# for given index $k$.
# Since our desirable probability distribution is Boltzmann distribution, and one component for transition probability is set as constant, the acceptance probability to association is defined by simple Boltzmann factor:
# \begin{equation}
# \alpha_{ik}^{A} = C\exp(-u_{ik}),
# \end{equation}
# where $C$ is normalization constant.
# Therefore, we have probability to association:
# \begin{equation}
# P_{ik}^{A} = \frac{C}{N_p -1}\exp(-u_{ik}).
# \end{equation}

# # Let $\pi_j$ be the equilibrium probability for state j. The detailed balance equation is defined by
# # \begin{equation}
# # \pi_i P_{ij} = \pi_j P_{ji},
# # \end{equation}
# # where $P_{ij}$ is the Markov transition probability from state i th state j. The transition probability, $P_{ij}$, can be decomposed by suggestion probability, $q_{ij}$, and acceptance probability, $\alpha_{ij}$:
# # \begin{equation}
# # P_{ij} = q_{ij}\alpha_{ij}.
# # \end{equation}



# # On this regards, we can define transition probability as Boltzmann factor:
# # \begin{equation}
# # \pi_{i}^{k} = \exp(-u_{ik}).
# # \end{equation}
# # Note that the real transiti


# # Simply, we can think about two way of selection: (i) selecting target particles randomly (equally probable) and using Boltzmann factor as acceptance proability or (ii) selection is follows the Boltzmann distribution, directly.




# *** Cut-off Radius
# This is of importance that introducing cut-off radius for efficiency should not affect to the statistics. The cut-off is highly related with the suggestion probability that make zero. When the acceptance probability is sufficiently approximated by zero, with random approximation, the suggestion probability is given by $1/N_p$ which in consequence the transition probability as approximately zero. Note that without this scheme, we have to account $N_p$ numbers of pairs for given specified bead, which in consequence, approximately $N_p^2$ pairs should be accounted for stochastic simulation (and we also considered total number of iterations for this pairs). Therefore, the cut-off scheme is not avoidable in order to compute the system within reasonable real time constraint. To be specific, let $N_{R_c}$ be number of particle within cut-off radius, $R_c$, then the transition probability becomes
# \begin{align}
# P_{ik} &= \frac{1}{N_{R_c}-1}\exp(-u_{ik})\quad\textrm{for } r_{ik} < R_c\\
# P_{ik} &= 0 \quad\textrm{for } r_{ik} \geq R_c.
# \end{align}

# The effect to the Metropolis algorithm should be studied.

* Simple Note for Compromise with the Previous Approach
Remain all the scheme, but using Boltzmann factor, which means the probability of the movement follows Boltzmann factor:
\begin{equation}
P(k|i\to j) = \frac{\exp(-u_{jk})}{\exp(-u_{ik})} = \exp\left(-(u_{jk}-u_{ik})\right),
\end{equation}
which is differ in the previous scheme:
\begin{equation}
P(k|i\to j) = P(k|k\to j) = P(k|j\to j) = \exp(-u_{jk}).
\end{equation}

** Partition function
It is of importance to think about partition function with proper normalization condtion. The sum of all the Boltzmann factor simply reduced by the current factor, $\exp(-u_{ik}):
\begin{equation}
Z_k^{mov} = \sum_{j=1}^{N_p} P'(k|i\to j) = \sum_{j=1}^{N_p} \exp(-u_{jk})\exp(u_{ik}).
\end{equation}
Therefore, we have
\begin{equation}
P(k|i\to j) = \exp(-u_{jk}\exp(u_{ik}) / Z_k^{mov} = \exp(-u_{jk})/\sum_{j=1}^{N_p}\exp(-u_{jk}) = \exp(-u_{jk})/Z_k,
\end{equation}
where $Z_k$ is the partition function that is used originally. 
Shortly, the additional factor will not affect the overall scheme.


* Figures
** Spectrum of potential energy state, freely move-able chains
#+CAPTION: Potential energy state spectrum based on the Gaussian connector
#+NAME: fig:state_map_log
#+ATTR_HTML: :width 640px
[[file:simplified_Boltzmann/exam_Np3_Nc3_counting_all_state.png]]

** Spectrum of potential energy state, chains restricted to original bead
#+CAPTION: Spectrum of potential energy state based on the Gaussian connector for chains constrainted to original bead
#+NAME: fig:state_map_log_constraint
#+ATTR_HTML: :width 640px
[[file:simplified_Boltzmann/exam_Np3_Nc3_individual.png]]

# * Scheme 1: equally probable to select chain and taking action with Boltzmann distribution
# Let assumed that we are randomly visiting bead, and also randomly visiting specific chain end that attached to visited bead. In principle, the visiting probability follows
# \begin{equation}
# \frac{1}{2N_CN_p},
# \end{equation}
# where $N_C$ is number of chains per bead and $N_p$ is number of beads. 
# Let say we are visiting k-th bead, 
# Then, the in-visited chain ends follows the Boltzmann distribution:
# \begin{equation}
# P'(
# \end{equation}
